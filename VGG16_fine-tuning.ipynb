{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bc5f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import random \n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "%matplotlib inline\n",
    "import PIL\n",
    "import time\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from pylab import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fff67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r\"D:\\Kenkyuu\\Shin Dataset\\train\"\n",
    "valid_path = r\"D:\\Kenkyuu\\Shin Dataset\\val\"\n",
    "test_path = r\"D:\\Kenkyuu\\Shin Dataset\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bd8ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = ImageDataGenerator() \\\n",
    "    .flow_from_directory(directory=train_path, target_size=(224,224), classes = ['0', '1'] , batch_size=10)\n",
    "valid_batches = ImageDataGenerator() \\\n",
    "    .flow_from_directory(directory=valid_path, target_size=(224,224), classes = ['0', '1'] , batch_size=10)\n",
    "test_batches = ImageDataGenerator() \\\n",
    "    .flow_from_directory(directory=test_path, target_size=(224,224), classes = ['0', '1'] , batch_size=10, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6902ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batches.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f535f723",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8bb96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model = tf.keras.applications.vgg16.VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9416a0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477818ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "for layer in vgg16_model.layers[:-1]:\n",
    "    model.add(layer)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc5bc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e15a5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5d3039",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1= time.time()\n",
    "history = model.fit(x=train_batches, validation_data=valid_batches, steps_per_epoch = 100, epochs=10, verbose=1)\n",
    "t2= time.time()\n",
    "print('Time taken was {} seconds'.format(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb151a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss =history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label = 'Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label = 'Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label = 'Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label = 'Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9788a5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import PIL\n",
    "\n",
    "dir_path = r\"D:\\Kenkyuu\\Shin Dataset\\test\\1\"\n",
    "\n",
    "t3= time.time()\n",
    "\n",
    "for i in os.listdir(dir_path):\n",
    "    img = image.load_img(dir_path+'\\\\'+ i, target_size=(224,224))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "    X = image.img_to_array(img)\n",
    "    X = np.expand_dims(X,axis=0)\n",
    "    images = np.vstack([X])\n",
    "    val = model.predict(images)\n",
    "    if val [0][0]> val[0][1]:\n",
    "        print(\"not landing target\")\n",
    "        print(val)\n",
    "    else:\n",
    "        print(\"landing target\")\n",
    "        print(val)\n",
    "        \n",
    "t4= time.time()\n",
    "print('Time taken was {} seconds'.format(t4-t3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3854f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import PIL\n",
    "\n",
    "dir_path = r\"D:\\Kenkyuu\\Shin Dataset\\test\\0\"\n",
    "\n",
    "t3= time.time()\n",
    "\n",
    "for i in os.listdir(dir_path):\n",
    "    img = image.load_img(dir_path+'\\\\'+ i, target_size=(224,224))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "    X = image.img_to_array(img)\n",
    "    X = np.expand_dims(X,axis=0)\n",
    "    images = np.vstack([X])\n",
    "    val = model.predict(images)\n",
    "    if val [0][0]> val[0][1]:\n",
    "        print(\"not landing target\")\n",
    "        print(val)\n",
    "    else:\n",
    "        print(\"landing target\")\n",
    "        print(val)\n",
    "t4= time.time()\n",
    "print('Time taken was {} seconds'.format(t4-t3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41267bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('models/landing_target_recognition_model_Softmax_Categorical.h5') is False:\n",
    "    model.save('models/landing_target_recognition_model_Softmax_Categorical.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
